We present the results of an Sarsa($\lambda$) based agent with a KL-UCB policy
and a maximiser. The agent acts in several different discrete state space
environments, two of which we authored and explain here; Tic-tac-toe and Connect
Four. Enabling the maximiser proved better in environments with large state
spaces. Using KL-UCB did not yield better results than a greedy Sarsa($\lambda$)
with $\lambda = 0.2, \alpha = 1$.
